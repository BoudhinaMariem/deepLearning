# ğŸ™ï¸ Audio Emotion Classification â€“ CREMA-D Dataset

## ğŸ“Œ About the Project
This project aims to classify human emotions from audio recordings, focusing on two categories:
- ğŸ˜„ Happy
- ğŸ˜¢ Sad

We convert each audio file into a **Mel-Spectrogram** and use Deep Learning models (CNN, ResNet50, and an Encoderâ€“Decoder Autoencoder) to learn emotion-specific acoustic patterns.

---

## ğŸ“‚ About the Dataset (CREMA-D)

**Dataset link:**  
https://www.kaggle.com/datasets/ejlok1/cremad

### ğŸ“Œ Context  
The CREMA-D dataset is widely used for speech emotion recognition because it contains **a large variety of speakers**, reducing information leakage and improving generalization.  
Unlike many audio datasets with few speakers, CREMA-D includes many actors, making it less prone to overfitting.

### ğŸ“Œ Content  
- **7,442** original audio clips  
- **91 actors** (48 males, 43 females)  
- Age range: **20â€“74 years**  
- Ethnic diversity: African American, Asian, Caucasian, Hispanic, Unspecified  
- Actors pronounce **12 different sentences**  
- Each sentence is performed with one of **6 emotions**:  
  **Anger, Disgust, Fear, Happy, Neutral, Sad**  
- 4 emotion intensity levels: Low, Medium, High, Unspecified  
- Audio format: `.wav`

---

## ğŸ› ï¸ Preprocessing
- Load audio with **Librosa**
- Convert waveform â†’ **Mel-Spectrogram**
- Apply normalization and padding to obtain a fixed-size spectrogram
- Split dataset into Train / Validation / Test

---

## ğŸ¤– Models Used

### 1ï¸âƒ£ **Autoencoder (Encoderâ€“Decoder)**
- Convolutional Encoder to learn compressed audio representations  
- Decoder to reconstruct spectrograms  
- Helps to improve feature extraction before classification

### 2ï¸âƒ£ **CNN From Scratch**
- Custom Convolutional Neural Network  
- Baseline model trained directly on Mel-Spectrograms

### 3ï¸âƒ£ **ResNet50 (Transfer Learning)**
- Pretrained on ImageNet  
- Used as a feature extractor on spectrogram images  
- Custom classification head added for emotion recognition

### 4ï¸âƒ£ **Fine-Tuned ResNet50**
- Unfreeze deeper layers  
- Lower learning rate for fine adjustment  
- Best performing model

---

## ğŸ“Š Results
| Model | Accuracy |
|-------|----------|
| Autoencoder features + classifier | ~85% |
| CNN from scratch | ~85â€“88% |
| ResNet50 | ~90â€“92% |
| **Fine-tuned ResNet50** | **~94â€“96%** |

---

## â–¶ï¸ Run the Notebook
```bash
pip install librosa tensorflow numpy matplotlib seaborn scikit-learn
jupyter notebook audio_deep.ipynb
